[
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About me",
    "section": "",
    "text": "Welcome to my home page, I’m a Data Science/Analytics specialist with more than a decade of work in many IT domains."
  },
  {
    "objectID": "resume.html",
    "href": "resume.html",
    "title": "Rafael Belokurows",
    "section": "",
    "text": "&lt;p&gt;&lt;/iframe&lt;/p&gt;\n&lt;section id=\"section\" class=\"level2\"&gt;\n&lt;h2&gt;&lt;/h2&gt;\n&lt;div id=\"quarto-navigation-envelope\" class=\"hidden\"&gt;\n&lt;p&gt;&lt;span class=\"hidden\" data-render-id=\"quarto-int-sidebar-title\"&gt;Rafael Belokurows&lt;/span&gt; &lt;span class=\"hidden\" data-render-id=\"quarto-int-navbar-title\"&gt;Rafael Belokurows&lt;/span&gt; &lt;span class=\"hidden\" data-render-id=\"quarto-int-navbar:Home\"&gt;Home&lt;/span&gt; &lt;span class=\"hidden\" data-render-id=\"quarto-int-navbar:/index.html\"&gt;/index.html&lt;/span&gt; &lt;span class=\"hidden\" data-render-id=\"quarto-int-navbar:Projects\"&gt;Projects&lt;/span&gt; &lt;span class=\"hidden\" data-render-id=\"quarto-int-navbar:/projects.html\"&gt;/projects.html&lt;/span&gt; &lt;span class=\"hidden\" data-render-id=\"quarto-int-navbar:Resume\"&gt;Resume&lt;/span&gt; &lt;span class=\"hidden\" data-render-id=\"quarto-int-navbar:/resume.html\"&gt;/resume.html&lt;/span&gt; &lt;span class=\"hidden\" data-render-id=\"quarto-int-navbar:Blog\"&gt;Blog&lt;/span&gt; &lt;span class=\"hidden\" data-render-id=\"quarto-int-navbar:/blog.html\"&gt;/blog.html&lt;/span&gt; &lt;span class=\"hidden\" data-render-id=\"quarto-int-navbar:Data Viz\"&gt;Data Viz&lt;/span&gt; &lt;span class=\"hidden\" data-render-id=\"quarto-int-navbar:/data-viz.html\"&gt;/data-viz.html&lt;/span&gt; &lt;span class=\"hidden\" data-render-id=\"quarto-int-navbar:https://github.com/rafabelokurows\"&gt;https://github.com/rafabelokurows&lt;/span&gt; &lt;span class=\"hidden\" data-render-id=\"quarto-int-navbar:https://www.linkedin.com/in/rafabelo\"&gt;https://www.linkedin.com/in/rafabelo&lt;/span&gt;&lt;/p&gt;\n&lt;div class=\"hidden\" data-render-id=\"footer-left\"&gt;\n&lt;p&gt;Made with &lt;a href=\"https://quarto.org/\"&gt;Quarto&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;\n&lt;div class=\"hidden\" data-render-id=\"footer-center\"&gt;\n&lt;p&gt;&lt;a href=\"mailto:rafabelokurows@gmail.com\"&gt;Rafael Belokurows&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;\n&lt;div class=\"hidden\" data-render-id=\"footer-right\"&gt;\n&lt;p&gt;&lt;a href=\"https://www.github.com/rafabelokurows/\"&gt;Github&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;\n&lt;/div&gt;\n&lt;div id=\"quarto-meta-markdown\" class=\"hidden\"&gt;\n&lt;p&gt;&lt;span class=\"hidden\" data-render-id=\"quarto-metatitle\"&gt;Rafael Belokurows&lt;/span&gt; &lt;span class=\"hidden\" data-render-id=\"quarto-twittercardtitle\"&gt;Rafael Belokurows&lt;/span&gt; &lt;span class=\"hidden\" data-render-id=\"quarto-ogcardtitle\"&gt;Rafael Belokurows&lt;/span&gt; &lt;span class=\"hidden\" data-render-id=\"quarto-metasitename\"&gt;Rafael Belokurows&lt;/span&gt; &lt;span class=\"hidden\" data-render-id=\"quarto-twittercarddesc\"&gt;&lt;/span&gt; &lt;span class=\"hidden\" data-render-id=\"quarto-ogcardddesc\"&gt;&lt;/span&gt;&lt;/p&gt;\n&lt;/div&gt;\n&lt;/section&gt;\n\n&lt;/main&gt; &lt;!-- /main --&gt;\n&lt;script id = \"quarto-html-after-body\" type=\"application/javascript\"&gt;\nwindow.document.addEventListener(\"DOMContentLoaded\", function (event) {\n  const toggleBodyColorMode = (bsSheetEl) =&gt; {\n    const mode = bsSheetEl.getAttribute(\"data-mode\");\n    const bodyEl = window.document.querySelector(\"body\");\n    if (mode === \"dark\") {\n      bodyEl.classList.add(\"quarto-dark\");\n      bodyEl.classList.remove(\"quarto-light\");\n    } else {\n      bodyEl.classList.add(\"quarto-light\");\n      bodyEl.classList.remove(\"quarto-dark\");\n    }\n  }\n  const toggleBodyColorPrimary = () =&gt; {\n    const bsSheetEl = window.document.querySelector(\"link#quarto-bootstrap\");\n    if (bsSheetEl) {\n      toggleBodyColorMode(bsSheetEl);\n    }\n  }\n  toggleBodyColorPrimary();  \n  const disableStylesheet = (stylesheets) =&gt; {\n    for (let i=0; i &lt; stylesheets.length; i++) {\n      const stylesheet = stylesheets[i];\n      stylesheet.rel = 'prefetch';\n    }\n  }\n  const enableStylesheet = (stylesheets) =&gt; {\n    for (let i=0; i &lt; stylesheets.length; i++) {\n      const stylesheet = stylesheets[i];\n      stylesheet.rel = 'stylesheet';\n    }\n  }\n  const manageTransitions = (selector, allowTransitions) =&gt; {\n    const els = window.document.querySelectorAll(selector);\n    for (let i=0; i &lt; els.length; i++) {\n      const el = els[i];\n      if (allowTransitions) {\n        el.classList.remove('notransition');\n      } else {\n        el.classList.add('notransition');\n      }\n    }\n  }\n  const toggleGiscusIfUsed = (isAlternate, darkModeDefault) =&gt; {\n    const baseTheme = document.querySelector('#giscus-base-theme')?.value ?? 'light';\n    const alternateTheme = document.querySelector('#giscus-alt-theme')?.value ?? 'dark';\n    let newTheme = '';\n    if(darkModeDefault) {\n      newTheme = isAlternate ? baseTheme : alternateTheme;\n    } else {\n      newTheme = isAlternate ? alternateTheme : baseTheme;\n    }\n    const changeGiscusTheme = () =&gt; {\n      // From: https://github.com/giscus/giscus/issues/336\n      const sendMessage = (message) =&gt; {\n        const iframe = document.querySelector('iframe.giscus-frame');\n        if (!iframe) return;\n        iframe.contentWindow.postMessage({ giscus: message }, 'https://giscus.app');\n      }\n      sendMessage({\n        setConfig: {\n          theme: newTheme\n        }\n      });\n    }\n    const isGiscussLoaded = window.document.querySelector('iframe.giscus-frame') !== null;\n    if (isGiscussLoaded) {\n      changeGiscusTheme();\n    }\n  }\n  const toggleColorMode = (alternate) =&gt; {\n    // Switch the stylesheets\n    const alternateStylesheets = window.document.querySelectorAll('link.quarto-color-scheme.quarto-color-alternate');\n    manageTransitions('#quarto-margin-sidebar .nav-link', false);\n    if (alternate) {\n      enableStylesheet(alternateStylesheets);\n      for (const sheetNode of alternateStylesheets) {\n        if (sheetNode.id === \"quarto-bootstrap\") {\n          toggleBodyColorMode(sheetNode);\n        }\n      }\n    } else {\n      disableStylesheet(alternateStylesheets);\n      toggleBodyColorPrimary();\n    }\n    manageTransitions('#quarto-margin-sidebar .nav-link', true);\n    // Switch the toggles\n    const toggles = window.document.querySelectorAll('.quarto-color-scheme-toggle');\n    for (let i=0; i &lt; toggles.length; i++) {\n      const toggle = toggles[i];\n      if (toggle) {\n        if (alternate) {\n          toggle.classList.add(\"alternate\");     \n        } else {\n          toggle.classList.remove(\"alternate\");\n        }\n      }\n    }\n    // Hack to workaround the fact that safari doesn't\n    // properly recolor the scrollbar when toggling (#1455)\n    if (navigator.userAgent.indexOf('Safari') &gt; 0 && navigator.userAgent.indexOf('Chrome') == -1) {\n      manageTransitions(\"body\", false);\n      window.scrollTo(0, 1);\n      setTimeout(() =&gt; {\n        window.scrollTo(0, 0);\n        manageTransitions(\"body\", true);\n      }, 40);  \n    }\n  }\n  const isFileUrl = () =&gt; { \n    return window.location.protocol === 'file:';\n  }\n  const hasAlternateSentinel = () =&gt; {  \n    let styleSentinel = getColorSchemeSentinel();\n    if (styleSentinel !== null) {\n      return styleSentinel === \"alternate\";\n    } else {\n      return false;\n    }\n  }\n  const setStyleSentinel = (alternate) =&gt; {\n    const value = alternate ? \"alternate\" : \"default\";\n    if (!isFileUrl()) {\n      window.localStorage.setItem(\"quarto-color-scheme\", value);\n    } else {\n      localAlternateSentinel = value;\n    }\n  }\n  const getColorSchemeSentinel = () =&gt; {\n    if (!isFileUrl()) {\n      const storageValue = window.localStorage.getItem(\"quarto-color-scheme\");\n      return storageValue != null ? storageValue : localAlternateSentinel;\n    } else {\n      return localAlternateSentinel;\n    }\n  }\n  const darkModeDefault = false;\n  let localAlternateSentinel = darkModeDefault ? 'alternate' : 'default';\n  // Dark / light mode switch\n  window.quartoToggleColorScheme = () =&gt; {\n    // Read the current dark / light value \n    let toAlternate = !hasAlternateSentinel();\n    toggleColorMode(toAlternate);\n    setStyleSentinel(toAlternate);\n    toggleGiscusIfUsed(toAlternate, darkModeDefault);\n  };\n  // Ensure there is a toggle, if there isn't float one in the top right\n  if (window.document.querySelector('.quarto-color-scheme-toggle') === null) {\n    const a = window.document.createElement('a');\n    a.classList.add('top-right');\n    a.classList.add('quarto-color-scheme-toggle');\n    a.href = \"\";\n    a.onclick = function() { try { window.quartoToggleColorScheme(); } catch {} return false; };\n    const i = window.document.createElement(\"i\");\n    i.classList.add('bi');\n    a.appendChild(i);\n    window.document.body.appendChild(a);\n  }\n  // Switch to dark mode if need be\n  if (hasAlternateSentinel()) {\n    toggleColorMode(true);\n  } else {\n    toggleColorMode(false);\n  }\n  const icon = \"\";\n  const anchorJS = new window.AnchorJS();\n  anchorJS.options = {\n    placement: 'right',\n    icon: icon\n  };\n  anchorJS.add('.anchored');\n  const isCodeAnnotation = (el) =&gt; {\n    for (const clz of el.classList) {\n      if (clz.startsWith('code-annotation-')) {                     \n        return true;\n      }\n    }\n    return false;\n  }\n  const clipboard = new window.ClipboardJS('.code-copy-button', {\n    text: function(trigger) {\n      const codeEl = trigger.previousElementSibling.cloneNode(true);\n      for (const childEl of codeEl.children) {\n        if (isCodeAnnotation(childEl)) {\n          childEl.remove();\n        }\n      }\n      return codeEl.innerText;\n    }\n  });\n  clipboard.on('success', function(e) {\n    // button target\n    const button = e.trigger;\n    // don't keep focus\n    button.blur();\n    // flash \"checked\"\n    button.classList.add('code-copy-button-checked');\n    var currentTitle = button.getAttribute(\"title\");\n    button.setAttribute(\"title\", \"Copied!\");\n    let tooltip;\n    if (window.bootstrap) {\n      button.setAttribute(\"data-bs-toggle\", \"tooltip\");\n      button.setAttribute(\"data-bs-placement\", \"left\");\n      button.setAttribute(\"data-bs-title\", \"Copied!\");\n      tooltip = new bootstrap.Tooltip(button, \n        { trigger: \"manual\", \n          customClass: \"code-copy-button-tooltip\",\n          offset: [0, -8]});\n      tooltip.show();    \n    }\n    setTimeout(function() {\n      if (tooltip) {\n        tooltip.hide();\n        button.removeAttribute(\"data-bs-title\");\n        button.removeAttribute(\"data-bs-toggle\");\n        button.removeAttribute(\"data-bs-placement\");\n      }\n      button.setAttribute(\"title\", currentTitle);\n      button.classList.remove('code-copy-button-checked');\n    }, 1000);\n    // clear code selection\n    e.clearSelection();\n  });\n    var localhostRegex = new RegExp(/^(?:http|https):\\/\\/localhost\\:?[0-9]*\\//);\n    var mailtoRegex = new RegExp(/^mailto:/);\n      var filterRegex = new RegExp('/' + window.location.host + '/');\n    var isInternal = (href) =&gt; {\n        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);\n    }\n    // Inspect non-navigation links and adorn them if external\n \tvar links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool)');\n    for (var i=0; i&lt;links.length; i++) {\n      const link = links[i];\n      if (!isInternal(link.href)) {\n        // undo the damage that might have been done by quarto-nav.js in the case of\n        // links that we want to consider external\n        if (link.dataset.originalHref !== undefined) {\n          link.href = link.dataset.originalHref;\n        }\n      }\n    }\n  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {\n    const config = {\n      allowHTML: true,\n      maxWidth: 500,\n      delay: 100,\n      arrow: false,\n      appendTo: function(el) {\n          return el.parentElement;\n      },\n      interactive: true,\n      interactiveBorder: 10,\n      theme: 'quarto',\n      placement: 'bottom-start',\n    };\n    if (contentFn) {\n      config.content = contentFn;\n    }\n    if (onTriggerFn) {\n      config.onTrigger = onTriggerFn;\n    }\n    if (onUntriggerFn) {\n      config.onUntrigger = onUntriggerFn;\n    }\n    window.tippy(el, config); \n  }\n  const noterefs = window.document.querySelectorAll('a[role=\"doc-noteref\"]');\n  for (var i=0; i&lt;noterefs.length; i++) {\n    const ref = noterefs[i];\n    tippyHover(ref, function() {\n      // use id or data attribute instead here\n      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');\n      try { href = new URL(href).hash; } catch {}\n      const id = href.replace(/^#\\/?/, \"\");\n      const note = window.document.getElementById(id);\n      if (note) {\n        return note.innerHTML;\n      } else {\n        return \"\";\n      }\n    });\n  }\n  const xrefs = window.document.querySelectorAll('a.quarto-xref');\n  const processXRef = (id, note) =&gt; {\n    // Strip column container classes\n    const stripColumnClz = (el) =&gt; {\n      el.classList.remove(\"page-full\", \"page-columns\");\n      if (el.children) {\n        for (const child of el.children) {\n          stripColumnClz(child);\n        }\n      }\n    }\n    stripColumnClz(note)\n    if (id === null || id.startsWith('sec-')) {\n      // Special case sections, only their first couple elements\n      const container = document.createElement(\"div\");\n      if (note.children && note.children.length &gt; 2) {\n        container.appendChild(note.children[0].cloneNode(true));\n        for (let i = 1; i &lt; note.children.length; i++) {\n          const child = note.children[i];\n          if (child.tagName === \"P\" && child.innerText === \"\") {\n            continue;\n          } else {\n            container.appendChild(child.cloneNode(true));\n            break;\n          }\n        }\n        if (window.Quarto?.typesetMath) {\n          window.Quarto.typesetMath(container);\n        }\n        return container.innerHTML\n      } else {\n        if (window.Quarto?.typesetMath) {\n          window.Quarto.typesetMath(note);\n        }\n        return note.innerHTML;\n      }\n    } else {\n      // Remove any anchor links if they are present\n      const anchorLink = note.querySelector('a.anchorjs-link');\n      if (anchorLink) {\n        anchorLink.remove();\n      }\n      if (window.Quarto?.typesetMath) {\n        window.Quarto.typesetMath(note);\n      }\n      // TODO in 1.5, we should make sure this works without a callout special case\n      if (note.classList.contains(\"callout\")) {\n        return note.outerHTML;\n      } else {\n        return note.innerHTML;\n      }\n    }\n  }\n  for (var i=0; i&lt;xrefs.length; i++) {\n    const xref = xrefs[i];\n    tippyHover(xref, undefined, function(instance) {\n      instance.disable();\n      let url = xref.getAttribute('href');\n      let hash = undefined; \n      if (url.startsWith('#')) {\n        hash = url;\n      } else {\n        try { hash = new URL(url).hash; } catch {}\n      }\n      if (hash) {\n        const id = hash.replace(/^#\\/?/, \"\");\n        const note = window.document.getElementById(id);\n        if (note !== null) {\n          try {\n            const html = processXRef(id, note.cloneNode(true));\n            instance.setContent(html);\n          } finally {\n            instance.enable();\n            instance.show();\n          }\n        } else {\n          // See if we can fetch this\n          fetch(url.split('#')[0])\n          .then(res =&gt; res.text())\n          .then(html =&gt; {\n            const parser = new DOMParser();\n            const htmlDoc = parser.parseFromString(html, \"text/html\");\n            const note = htmlDoc.getElementById(id);\n            if (note !== null) {\n              const html = processXRef(id, note);\n              instance.setContent(html);\n            } \n          }).finally(() =&gt; {\n            instance.enable();\n            instance.show();\n          });\n        }\n      } else {\n        // See if we can fetch a full url (with no hash to target)\n        // This is a special case and we should probably do some content thinning / targeting\n        fetch(url)\n        .then(res =&gt; res.text())\n        .then(html =&gt; {\n          const parser = new DOMParser();\n          const htmlDoc = parser.parseFromString(html, \"text/html\");\n          const note = htmlDoc.querySelector('main.content');\n          if (note !== null) {\n            // This should only happen for chapter cross references\n            // (since there is no id in the URL)\n            // remove the first header\n            if (note.children.length &gt; 0 && note.children[0].tagName === \"HEADER\") {\n              note.children[0].remove();\n            }\n            const html = processXRef(null, note);\n            instance.setContent(html);\n          } \n        }).finally(() =&gt; {\n          instance.enable();\n          instance.show();\n        });\n      }\n    }, function(instance) {\n    });\n  }\n      let selectedAnnoteEl;\n      const selectorForAnnotation = ( cell, annotation) =&gt; {\n        let cellAttr = 'data-code-cell=\"' + cell + '\"';\n        let lineAttr = 'data-code-annotation=\"' +  annotation + '\"';\n        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';\n        return selector;\n      }\n      const selectCodeLines = (annoteEl) =&gt; {\n        const doc = window.document;\n        const targetCell = annoteEl.getAttribute(\"data-target-cell\");\n        const targetAnnotation = annoteEl.getAttribute(\"data-target-annotation\");\n        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));\n        const lines = annoteSpan.getAttribute(\"data-code-lines\").split(\",\");\n        const lineIds = lines.map((line) =&gt; {\n          return targetCell + \"-\" + line;\n        })\n        let top = null;\n        let height = null;\n        let parent = null;\n        if (lineIds.length &gt; 0) {\n            //compute the position of the single el (top and bottom and make a div)\n            const el = window.document.getElementById(lineIds[0]);\n            top = el.offsetTop;\n            height = el.offsetHeight;\n            parent = el.parentElement.parentElement;\n          if (lineIds.length &gt; 1) {\n            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);\n            const bottom = lastEl.offsetTop + lastEl.offsetHeight;\n            height = bottom - top;\n          }\n          if (top !== null && height !== null && parent !== null) {\n            // cook up a div (if necessary) and position it \n            let div = window.document.getElementById(\"code-annotation-line-highlight\");\n            if (div === null) {\n              div = window.document.createElement(\"div\");\n              div.setAttribute(\"id\", \"code-annotation-line-highlight\");\n              div.style.position = 'absolute';\n              parent.appendChild(div);\n            }\n            div.style.top = top - 2 + \"px\";\n            div.style.height = height + 4 + \"px\";\n            div.style.left = 0;\n            let gutterDiv = window.document.getElementById(\"code-annotation-line-highlight-gutter\");\n            if (gutterDiv === null) {\n              gutterDiv = window.document.createElement(\"div\");\n              gutterDiv.setAttribute(\"id\", \"code-annotation-line-highlight-gutter\");\n              gutterDiv.style.position = 'absolute';\n              const codeCell = window.document.getElementById(targetCell);\n              const gutter = codeCell.querySelector('.code-annotation-gutter');\n              gutter.appendChild(gutterDiv);\n            }\n            gutterDiv.style.top = top - 2 + \"px\";\n            gutterDiv.style.height = height + 4 + \"px\";\n          }\n          selectedAnnoteEl = annoteEl;\n        }\n      };\n      const unselectCodeLines = () =&gt; {\n        const elementsIds = [\"code-annotation-line-highlight\", \"code-annotation-line-highlight-gutter\"];\n        elementsIds.forEach((elId) =&gt; {\n          const div = window.document.getElementById(elId);\n          if (div) {\n            div.remove();\n          }\n        });\n        selectedAnnoteEl = undefined;\n      };\n        // Handle positioning of the toggle\n    window.addEventListener(\n      \"resize\",\n      throttle(() =&gt; {\n        elRect = undefined;\n        if (selectedAnnoteEl) {\n          selectCodeLines(selectedAnnoteEl);\n        }\n      }, 10)\n    );\n    function throttle(fn, ms) {\n    let throttle = false;\n    let timer;\n      return (...args) =&gt; {\n        if(!throttle) { // first call gets through\n            fn.apply(this, args);\n            throttle = true;\n        } else { // all the others get throttled\n            if(timer) clearTimeout(timer); // cancel #2\n            timer = setTimeout(() =&gt; {\n              fn.apply(this, args);\n              timer = throttle = false;\n            }, ms);\n        }\n      };\n    }\n      // Attach click handler to the DT\n      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');\n      for (const annoteDlNode of annoteDls) {\n        annoteDlNode.addEventListener('click', (event) =&gt; {\n          const clickedEl = event.target;\n          if (clickedEl !== selectedAnnoteEl) {\n            unselectCodeLines();\n            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');\n            if (activeEl) {\n              activeEl.classList.remove('code-annotation-active');\n            }\n            selectCodeLines(clickedEl);\n            clickedEl.classList.add('code-annotation-active');\n          } else {\n            // Unselect the line\n            unselectCodeLines();\n            clickedEl.classList.remove('code-annotation-active');\n          }\n        });\n      }\n  const findCites = (el) =&gt; {\n    const parentEl = el.parentElement;\n    if (parentEl) {\n      const cites = parentEl.dataset.cites;\n      if (cites) {\n        return {\n          el,\n          cites: cites.split(' ')\n        };\n      } else {\n        return findCites(el.parentElement)\n      }\n    } else {\n      return undefined;\n    }\n  };\n  var bibliorefs = window.document.querySelectorAll('a[role=\"doc-biblioref\"]');\n  for (var i=0; i&lt;bibliorefs.length; i++) {\n    const ref = bibliorefs[i];\n    const citeInfo = findCites(ref);\n    if (citeInfo) {\n      tippyHover(citeInfo.el, function() {\n        var popup = window.document.createElement('div');\n        citeInfo.cites.forEach(function(cite) {\n          var citeDiv = window.document.createElement('div');\n          citeDiv.classList.add('hanging-indent');\n          citeDiv.classList.add('csl-entry');\n          var biblioDiv = window.document.getElementById('ref-' + cite);\n          if (biblioDiv) {\n            citeDiv.innerHTML = biblioDiv.innerHTML;\n          }\n          popup.appendChild(citeDiv);\n        });\n        return popup.innerHTML;\n      });\n    }\n  }\n});\n&lt;/script&gt;\n&lt;/div&gt; &lt;!-- /content --&gt;\n&lt;footer class=\"footer\"&gt;\n  &lt;div class=\"nav-footer\"&gt;\n    &lt;div class=\"nav-footer-left\"&gt;\n      &lt;div class='footer-contents'&gt;Made with [Quarto](https://quarto.org/)\n&lt;/div&gt;  \n    &lt;/div&gt;   \n    &lt;div class=\"nav-footer-center\"&gt;\n      &lt;div class='footer-contents'&gt;[Rafael Belokurows](mailto:rafabelokurows@gmail.com)\n&lt;/div&gt;  \n    &lt;/div&gt;\n    &lt;div class=\"nav-footer-right\"&gt;\n      &lt;div class='footer-contents'&gt;[Github](https://www.github.com/rafabelokurows/)\n&lt;/div&gt;  \n    &lt;/div&gt;\n  &lt;/div&gt;\n&lt;/footer&gt;\n\n&lt;/body&gt;\n\n&lt;/html&gt;"
  },
  {
    "objectID": "projects/welcome/index.html",
    "href": "projects/welcome/index.html",
    "title": "Welcome To My Blog",
    "section": "",
    "text": "This is the first post in a Quarto blog. Welcome!\n\nSince this post doesn’t specify an explicit image, the first image in the post will be used in the listing page of posts."
  },
  {
    "objectID": "projects/post-with-code/index.html",
    "href": "projects/post-with-code/index.html",
    "title": "Primeiro projeto",
    "section": "",
    "text": "This is a post with executable code.\n\nCode1 + 1\n\n[1] 2"
  },
  {
    "objectID": "data-viz.html",
    "href": "data-viz.html",
    "title": "Data Visualizations",
    "section": "",
    "text": "Time Series Anomaly Detection\n\n\n\n\n\nProphet Forecast\n\n\n\n\n\nInflation animation\n\n\n\n\n\nTop European Airlines\n\n\n\n\n\nGender pay gap in Eruopean countries\n\n\n\n\n\nInflation comparison 2022 x 2023"
  },
  {
    "objectID": "blog_posts/post-with-code/index.html",
    "href": "blog_posts/post-with-code/index.html",
    "title": "Churn prediction project",
    "section": "",
    "text": "This post is under construction\n\n\nCode\nimport pandas as pd\n\ndata = {\n  \"calories\": [420, 380, 390],\n  \"duration\": [50, 40, 45]\n}\n\n#load data into a DataFrame object:\ndf = pd.DataFrame(data)\n\nprint(df);\n\n\n   calories  duration\n0       420        50\n1       380        40\n2       390        45"
  },
  {
    "objectID": "blog.html",
    "href": "blog.html",
    "title": "Rafael Belokurows",
    "section": "",
    "text": "Worlwide Weather Data\n\n\n9 min\n\n\n\nR\n\n\nweather\n\n\npackages\n\n\ngeo\n\n\ndata\n\n\n\nObtain daily weather data for weather stations all over the world with a few lines of code + some plots to get you started\n\n\n\nMay 15, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nR tip #1: Don’t lose track of your outputs with ‘.Last.value’\n\n\n2 min\n\n\n\ntips\n\n\nR\n\n\nprogramming\n\n\nRStudio\n\n\n\nUse .Last.value on R to keep data you forgot to save to a variable\n\n\n\nMay 7, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nChurn prediction project\n\n\n1 min\n\n\n\nnews\n\n\ncode\n\n\nanalysis\n\n\n\n\n\n\n\nJan 1, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nObtaining data from tables in PDF files\n\n\n3 min\n\n\n\nunder_construction\n\n\npdf\n\n\nocr\n\n\nR\n\n\n\nUnder construction\n\n\n\nJan 1, 2024\n\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "blog_posts/welcome/index.html",
    "href": "blog_posts/welcome/index.html",
    "title": "R tip #1: Don’t lose track of your outputs with ‘.Last.value’",
    "section": "",
    "text": "Greetings!\nA quick R tip to get thins going:\nIf you’re a bit distracted like me and you sometimes forget to store your variables or outputs, having to run the same function more than once, like so:\nCodedata.frame(a=c(1,2,3),b=c(4,5,6)) #oops, forgot to save it to a variable\n\n  a b\n1 1 4\n2 2 5\n3 3 6\nInstead of doing this :\nCodedf &lt;- data.frame(a=c(1,2,3),b=c(4,5,6)) #there you go\ndf\n\n  a b\n1 1 4\n2 2 5\n3 3 6\nThen I might have the solution for you. Base R has a function called .Last.value1 that recalls and lets you reuse your last console output (be it whatever it is).\nThis way, you can store it in a variable and do whatever you wanted to do with it in the first place!\nYou may ask me: Ok, but how will that save me time? Can’t I press the up arrow ⬆ and run the same code again? Yeah, sure, but what if you just ran a complex operation on a dataframe with many thousands of rows (or more)?\nUsing .Last.value lets you reuse the same data, this way you won’t waste time or computing power (which in a hosted environment could cost you some money).\nThis is the first of a series of tips to come, stay tuned for more!"
  },
  {
    "objectID": "data_viz/post-with-code/index.html",
    "href": "data_viz/post-with-code/index.html",
    "title": "Primeiro post blog",
    "section": "",
    "text": "This is a post with executable code.\n\nCode1 + 1\n\n[1] 2"
  },
  {
    "objectID": "projects/post_with_plot/index.html",
    "href": "projects/post_with_plot/index.html",
    "title": "Segundo projeto",
    "section": "",
    "text": "This is a post with executable code.\n\nCodeplot(mtcars$mpg)"
  },
  {
    "objectID": "projects.html",
    "href": "projects.html",
    "title": "Rafael Belokurows",
    "section": "",
    "text": "Streamlit app that allows the user to load their own time series CSV file and that gives a quick overview of time series features, perform statistical checks and produce short-term forecasts.\nLive Web App\nPowered by: Python, Streamlit, Prophet, time series libraries"
  },
  {
    "objectID": "projects.html#time-series-explorer-web-app",
    "href": "projects.html#time-series-explorer-web-app",
    "title": "Rafael Belokurows",
    "section": "",
    "text": "Streamlit app that allows the user to load their own time series CSV file and that gives a quick overview of time series features, perform statistical checks and produce short-term forecasts.\nLive Web App\nPowered by: Python, Streamlit, Prophet, time series libraries"
  },
  {
    "objectID": "projects.html#porto-street-names-gender-gap",
    "href": "projects.html#porto-street-names-gender-gap",
    "title": "Rafael Belokurows",
    "section": "Porto Street Names Gender Gap",
    "text": "Porto Street Names Gender Gap\n\n\n\n\n\n\nMost cities have a long-standing gender bias towards men when naming streets, squares, gardens, and other public places. While there is a somewhat recent trend to include more women when defining city names, most street names are well-established and hard to change. With this in mind, I analyzed how bad is the gender bias where I live: Porto, Portugal.\nGithub Repo\nPowered by: R, leaflet, openstreetmaps data"
  },
  {
    "objectID": "projects.html#flight-explorer",
    "href": "projects.html#flight-explorer",
    "title": "Rafael Belokurows",
    "section": "Flight Explorer",
    "text": "Flight Explorer\n\n\nAutomated data pipeline that collects daily prices on plane tickets and send e-mail alerts whenever price drops below certain threshold in routes of interest.\nLive Web app\nMade using: Python, API requests, Github Actions, Google Big Query"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Rafael Belokurows",
    "section": "",
    "text": "Welcome to my webpage. Here you’ll find a bit about me, read some blog posts (that you’ll hopefully like), check tips and tricks on Data Analysis and Data Science tools, and see some of the stuff I’ve been working on lately. On the professional side, I’m currently working in Analytics/Data Science at Kantar Worldpanel Portugal. In real life, I enjoy reading fiction, biking and traveling.\nTo see some examples of my work and personal projects, check out:\nResume\nData projects\nBlog\nData visualizations"
  },
  {
    "objectID": "index.html#about-me",
    "href": "index.html#about-me",
    "title": "Rafael Belokurows",
    "section": "",
    "text": "Welcome to my webpage. Here you’ll find a bit about me, read some blog posts (that you’ll hopefully like), check tips and tricks on Data Analysis and Data Science tools, and see some of the stuff I’ve been working on lately. On the professional side, I’m currently working in Analytics/Data Science at Kantar Worldpanel Portugal. In real life, I enjoy reading fiction, biking and traveling.\nTo see some examples of my work and personal projects, check out:\nResume\nData projects\nBlog\nData visualizations"
  },
  {
    "objectID": "index.html#areas-of-interest",
    "href": "index.html#areas-of-interest",
    "title": "Rafael Belokurows",
    "section": "Areas of interest",
    "text": "Areas of interest\n🛒 Consumer trends, Churn prevention, Customer Segmentation\n📊 Product usability metrics, A/B tests\n💹 Time Series Analysis and Forecasting\n🌎 Geographical Models, Transport and Urban Planning\n🌲 Environment, Climate Change, and Sustainability\n Web scraping and process automation\n🏈 Football, Baseball, Soccer"
  },
  {
    "objectID": "index.html#experience",
    "href": "index.html#experience",
    "title": "Rafael Belokurows",
    "section": "Experience",
    "text": "Experience\nKantar Worldpanel | Analytics/Data Science | Apr 2022 - Now"
  },
  {
    "objectID": "index.html#education",
    "href": "index.html#education",
    "title": "Rafael Belokurows",
    "section": "Education",
    "text": "Education\nUniversidade do Porto | Porto, Portugal Msc in Data Science | Sep 2021"
  },
  {
    "objectID": "data-viz - Copy.html",
    "href": "data-viz - Copy.html",
    "title": "Data Visualizations",
    "section": "",
    "text": "#TidyTuesday is a weekly data project aimed at the R ecosystem. This project was borne out of the R4DS Online Learning Community and the R for Data Science textbook. Emphasis is placed on understanding how to summarize and arrange data to make meaningful charts with ggplot2, tidyr, dplyr, and other tools in the tidyverse ecosystem. However, any code-based methodology is welcome.\nWhile I regularly participate in weekly Tidy Tuesday, these posts highlight my favorite submissions and the corresponding code.\n\n\n\n\n\n\nTip\n\n\n\nYou can find my github code repository for Tidy Tuesday submissions here.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPrimeiro post blog\n\n\n\nnews\n\n\ncode\n\n\nanalysis\n\n\n\n\n\n\n\nRafael Belokurows\n\n\nMar 29, 2024\n\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "projects.html#flight-explorer-1",
    "href": "projects.html#flight-explorer-1",
    "title": "Rafael Belokurows",
    "section": "Flight Explorer",
    "text": "Flight Explorer\n\n\n\n\nFully automated Quarto report of Portuguese Economy and Tourism indicators. Programed on Git Hub Actions and hosted on GitHub Pages, it automatically retrieves data from Portugues official statistics sources and compare latest data with historical results to give the user a quick overview of the situation of the economy and tourism in Portugal. Live Website\nMade with: R, leaflet, openstreetmaps data"
  },
  {
    "objectID": "projects.html#portugal-automated-kpi-report",
    "href": "projects.html#portugal-automated-kpi-report",
    "title": "Rafael Belokurows",
    "section": "Portugal automated KPI Report",
    "text": "Portugal automated KPI Report\n\n\n\n\n\n\nFully automated Quarto report of Portuguese Economy and Tourism indicators. Programed on Git Hub Actions and hosted on GitHub Pages, it automatically retrieves data from Portugues official statistics sources and compare latest data with historical results to give the user a quick overview of the situation of the economy and tourism in Portugal.\nPowered by: Python, Quarto, Github Actions, GitHub Pages\nLive Website\nGithub Repo"
  },
  {
    "objectID": "blog_posts/welcome/index.html#footnotes",
    "href": "blog_posts/welcome/index.html#footnotes",
    "title": "R tip #1: Don’t lose track of your outputs with ‘.Last.value’",
    "section": "Footnotes",
    "text": "Footnotes\n\nFor more (but not whole more of a lot) on this function, there’s always R’s documentation.↩︎"
  },
  {
    "objectID": "blog_posts/r_tip_2/r_tip_2.html",
    "href": "blog_posts/r_tip_2/r_tip_2.html",
    "title": "R Tip #2",
    "section": "",
    "text": "Greetings!\nA quick R tip to get thins going:\nIf you’re a bit distracted like me and you sometimes forget to store your variables or outputs, having to run the same function more than once, like so:\nCodedata.frame(a=c(1,2,3),b=c(4,5,6)) #oops, forgot to save it to a variable\n\n  a b\n1 1 4\n2 2 5\n3 3 6\nInstead of doing this :\nCodedf &lt;- data.frame(a=c(1,2,3),b=c(4,5,6)) #there you go\ndf\n\n  a b\n1 1 4\n2 2 5\n3 3 6\nThen I might have the solution for you. Base R has a function called .Last.value1 that recalls and lets you reuse your last console output (be it whatever it is).\nThis way, you can store it in a variable and do whatever you wanted to do with it in the first place!\nYou may ask me: Ok, but how will that save me time? Can’t I press the up arrow ⬆ and run the same code again? Yeah, sure, but what if you just ran a complex operation on a dataframe with many thousands of rows (or more)?\nUsing .Last.value lets you reuse the same data, this way you won’t waste time or computing power (which in a hosted environment could cost you some money).\nThis is the first of a series of tips to come, stay tuned for more!"
  },
  {
    "objectID": "blog_posts/r_tip_2/r_tip_2.html#footnotes",
    "href": "blog_posts/r_tip_2/r_tip_2.html#footnotes",
    "title": "R Tip #2",
    "section": "Footnotes",
    "text": "Footnotes\n\nFor more (but not whole more of a lot) on this function, there’s always R’s documentation.↩︎"
  },
  {
    "objectID": "blog_posts/scraping_pdf_tables/scraping_pdf_tables.html",
    "href": "blog_posts/scraping_pdf_tables/scraping_pdf_tables.html",
    "title": "Obtaining data from tables in PDF files",
    "section": "",
    "text": "Hey, data people!\nI think this one will speak directly to the heart of everyone working with/in Data: You know how PDF files can be at the same time your salvation or your doom? Sometimes, you’ll find the exact piece of information you needed in a PDF on the far reaches of the wide web. On the other hand, a PDF file can also leave you hanging when you needed it the most when you simply cannot convert one table within a PDF file into an usable format fast enough.\nIn this post, you’ll see how to scrape data effectively and swiftly from a PDF with and without tables."
  },
  {
    "objectID": "blog_posts/scraping_pdf_tables/scraping_pdf_tables.html#footnotes",
    "href": "blog_posts/scraping_pdf_tables/scraping_pdf_tables.html#footnotes",
    "title": "Obtaining data from tables in PDF files",
    "section": "Footnotes",
    "text": "Footnotes\n\nhttps://github.com/tesseract-ocr/tesseract↩︎"
  },
  {
    "objectID": "blog_posts/r_tip_2/weather_data_r.html",
    "href": "blog_posts/r_tip_2/weather_data_r.html",
    "title": "Worlwide Weather Data",
    "section": "",
    "text": "Hello, Data people!\nIn this post, I’ll show you a great source of daily weather data for your ML projects or personal needs.\nI’m talking about R package GSODR which facilitates obtaining data from the NOAA’s Global Summary of the Day (GSOD). The GSOD is a summary of daily weather conditions based on underlying hourly data points measured at more than 9,000 global weather stations.1 Check out NOAA’s webpage fore more details on it.\nSome of the weather features available include, for each day:\nFor an exhaustive list of all the features available, check here."
  },
  {
    "objectID": "blog_posts/r_tip_2/weather_data_r.html#footnotes",
    "href": "blog_posts/r_tip_2/weather_data_r.html#footnotes",
    "title": "Worlwide Weather Data",
    "section": "Footnotes",
    "text": "Footnotes\n\nhttps://www.ncei.noaa.gov/access/metadata/landing-page/bin/iso?id=gov.noaa.ncdc:C00516↩︎\nhttps://dcl-wrangle.stanford.edu/pivot-advanced.html↩︎"
  },
  {
    "objectID": "blog_posts/r_tip_2/weather_data_r.html#obtaining-the-data",
    "href": "blog_posts/r_tip_2/weather_data_r.html#obtaining-the-data",
    "title": "Worlwide Weather Data",
    "section": "Obtaining the data",
    "text": "Obtaining the data\nGSODR is available on CRAN, so installing it is as easy as install.packages(\"GSODR\").\nLet’s find if a particular place has some weather stations near by. First, when you install the package, it stores a list of stations in a local database, from there, you can look up a country or a place (station name).\n\nCodelibrary(GSODR)\nload(system.file(\"extdata\", \"isd_history.rda\", package = \"GSODR\"))\nisd_history %&gt;% filter(COUNTRY_NAME == \"CANADA\") %&gt;% select(STNID,NAME,LAT,LON,COUNTRY_NAME) %&gt;% head() %&gt;%  gt()\n\n\n\n\n\n\nSTNID\nNAME\nLAT\nLON\nCOUNTRY_NAME\n\n\n\n693840-99999\nBOW DRILL\n44.000\n-59.333\nCANADA\n\n\n693850-99999\nGLOMAR HIGH ISLAND\n47.167\n-62.833\nCANADA\n\n\n693860-99999\nDRURY CREEK\n62.200\n-134.383\nCANADA\n\n\n693870-99999\nCARMACKS\n62.117\n-136.183\nCANADA\n\n\n693880-99999\nKLONDIKE\n64.450\n-138.217\nCANADA\n\n\n693900-99999\nSHELDON LAKE\n62.617\n-131.267\nCANADA\n\n\n\n\n\n\n\nTIP: It’s a good practice to run GSODR::update_station_list() every once in a while to force-update the list of weather stations available.\nIt’s pretty easy to plot an interactive map of the weather stations that we just identified:\n\nCodeleaflet(data = isd_history %&gt;% filter(COUNTRY_NAME == \"CANADA\") %&gt;% \n          filter(!grepl(\"GRATES COVE\",NAME)) %&gt;% sample_n(100)) %&gt;% addTiles() %&gt;%\n  addMarkers(~LON, ~LAT, popup = ~as.character(NAME), label = ~as.character(NAME))\n\n\n\n\n\nObs: I’m sampling randomly only 100 weather stations so the map is lighter, but there are around 2K stations in Canada alone. 🤯\nAnother important function of this package is nearest_stations, which allows to find the nearest stations based on the geographical coordinates you provide. For instance, when looking up Toronto’s Downtown coordinates, we see a few stations nearby:\n\nCode(nearby_stations = nearest_stations(LAT = 43.653,LON = -79.384,\n                                    distance = 10) %&gt;% \n  select(STNID,NAME,LAT,LON,COUNTRY_NAME,distance_km)) %&gt;% gt()\n\n\n\n\n\n\nSTNID\nNAME\nLAT\nLON\nCOUNTRY_NAME\ndistance_km\n\n\n\n715080-99999\nTORONTO CITY ONT\n43.667\n-79.400\nCANADA\n2.0\n\n\n712654-99999\nTORONTO ISL (MARS)\n43.633\n-79.400\nCANADA\n2.6\n\n\n726247-99999\nTORONTO IL ARPT AUT\n43.633\n-79.400\nCANADA\n2.6\n\n\n712650-99999\nTORONTO CITY CENTRE\n43.617\n-79.383\nCANADA\n4.0\n\n\n\n\n\n\nCodeleaflet(data = nearby_stations) %&gt;% addTiles() %&gt;%\n  addMarkers(~LON, ~LAT, popup = ~as.character(NAME), label = ~as.character(NAME))\n\n\n\n\n\nWhen you’re finished choosing one or multiple stations, the next step is obtaining the actual data for them:\n\nCode(weather_data = get_GSOD(years = c(2020:2024), station = \"712650-99999\") %&gt;% \n   select(STNID,NAME,MONTH,DAY,YEAR,TEMP,MAX,MIN,RH, I_FOG ,SLP,WDSP,PRCP,DATE = YEARMODA)) %&gt;% tail(5) %&gt;% gt()\n\n\n\n\n\n\nSTNID\nNAME\nMONTH\nDAY\nYEAR\nTEMP\nMAX\nMIN\nRH\nI_FOG\nSLP\nWDSP\nPRCP\nDATE\n\n\n\n712650-99999\nTORONTO CITY CENTRE\n5\n8\n2024\n14.7\n21.6\n7.1\n65.5\n1\n1001.8\n7.5\n5.08\n2024-05-08\n\n\n712650-99999\nTORONTO CITY CENTRE\n5\n9\n2024\n12.3\n21.6\n9.2\n71.5\n0\n1009.9\n3.1\n0.00\n2024-05-09\n\n\n712650-99999\nTORONTO CITY CENTRE\n5\n10\n2024\n13.2\n14.6\n9.2\n59.2\n0\n1009.4\n3.6\n0.00\n2024-05-10\n\n\n712650-99999\nTORONTO CITY CENTRE\n5\n11\n2024\n10.9\n13.0\n8.0\n80.1\n1\n1007.4\n3.0\n0.00\n2024-05-11\n\n\n712650-99999\nTORONTO CITY CENTRE\n5\n12\n2024\n11.9\n17.5\n8.2\n81.3\n1\n1008.5\n4.4\n1.78\n2024-05-12\n\n\n\n\n\n\n\nTIP: You can also get data for multiple years and/or multiple stations at once."
  },
  {
    "objectID": "blog_posts/r_tip_2/weather_data_r.html#plots",
    "href": "blog_posts/r_tip_2/weather_data_r.html#plots",
    "title": "Worlwide Weather Data",
    "section": "Plots",
    "text": "Plots\nHaving gotten the data, there are tons of interesting things to plot. I’ll show you some examples, feel free to get inspire and create even better looking plots :)\nExample 1: Temperature as lines\nHere, I’m plotting Maximum (red) and Minimum temperatures each day for over 2 years of Toronto weather data, which we’ve obtained in the previous step.\nThere is also quite some customization going on, such as:\n\nSmooth line for the two series (minimum and maximum)\nChanging size of fonts\nDisabling legend\nChanging color palette to use colors widely identifiable as “cold” and “heat”\n\nTIP: As many other ggplot2 situations, it’s a good practice to transform your data to “long format” using pivot_longer to transform it to name/value pairs.2\n\nCodeggplot(temperatures, aes(x=DATE, y=value, color=temp, linetype=temp)) + \n  geom_point() + \n  scale_colour_brewer(palette=\"Set1\") +\n  geom_smooth(span = 0.1) +\n  ggtitle(\"Toronto City Centre daily Min. and Max. Temperatures (2022-2024)\") +   \n  theme(plot.title=element_text(size=18, face=\"bold\"),\n        axis.title.y=element_text(size=15),legend.position = \"None\",\n        legend.text=element_text(size=13),\n        axis.title.x=element_text(size=16)) + \n  labs(x =NULL, y= expression(paste(\"Temperature (\",degree,\"C)\")))+theme_few() #scale_y_continuous(limits=c(-30, 50)) + scale_x_continuous(limits=c(0, 200)) \n\n\n\n\n\n\n\nExample 2: Rainy Days By Season\nWith this plot, I wanted to see the difference in the number of rainy days from one season to another. It should be interesting also to compare this aspect for different regions that have dry/wet seasons in different parts of the year. The first roadblock here was: how to define what is a season based on the dates, since weather seasons change in different days of the month and you also have to break months in parts. For that purpose, I’ve borrowed a function I had seen on Stack Overflow and made some concessions to get to a quicker solution setting season change dates always on the 21th, for the sake of simplicity. 😆\n\nShow the codeweather_data$rained = ifelse(weather_data$PRCP == 0 | is.na(weather_data$PRCP),\"No Rain\",\"Rain\")\n\n#Based on the code obtained from:\n#https://stackoverflow.com/questions/9500114/find-which-season-a-particular-date-belongs-to\ntoSeason &lt;- function(dat) {\n  stopifnot(class(dat) == \"Date\")\n  scalarCheck &lt;- function(dat) {\n    m &lt;- as.POSIXlt(dat)$mon+ 1        # correct for 0:11 range\n    d &lt;- as.POSIXlt(dat)$mday           # correct for 0:11 range\n    if ((m == 3 & d &gt;= 21) | (m == 4) | (m == 5) | (m == 6 & d &lt; 21)) {\n      r &lt;- 1\n    } else if ((m == 6 & d &gt;= 21) | (m == 7) | (m == 8) | (m == 9 & d &lt; 21)) {\n      r &lt;- 2\n    } else if ((m == 9 & d &gt;= 21) | (m == 10) | (m == 11) | (m == 12 & d &lt; 21)) {\n      r &lt;- 3\n    } else {\n      r &lt;- 4\n    }\n    r\n  }\n  res &lt;- sapply(dat, scalarCheck)\n  res &lt;- ordered(res, labels=c(\"Spring\", \"Summer\", \"Fall\", \"Winter\"))\n  invisible(res)\n}\nweather_data$season = toSeason(weather_data$DATE)\n\n\nHaving done that, we can then plot a 100% stacked bar chart of each Season and on how many days it rained for each one. As you can see for this particular case, Season were more homogeneous in terms of rain in Toronto in 2023.\n\nCodeweather_data %&gt;% \n  filter(YEAR %in% c(2022,2023)) %&gt;%\n  ggplot(aes(x = season,fill=rained)) +\n  geom_bar( position=\"fill\") +\n  stat_count(geom = \"text\", \n             aes(label = ..count..),\n             position=position_fill(vjust=0.5), colour=\"black\")+\n  scale_fill_manual(values = c(\"#EDEFBD\",\"#ACD1E9\"))+\n  ggtitle(\"Rainy Days in Toronto, by Season (2022 and 2023)\") +\n  labs(fill = NULL, x=NULL, y=\"% of days\")+\n  scale_y_continuous(labels = scales::percent_format())+\n  facet_grid(~YEAR)+theme_few()\n\n\n\n\n\n\n\nExample 3: Horizon Plots to visualize temperature changes over the years\nOkay, I can’t remember where I’ve seen this one, but I thought it was an ingenious way of plotting something like daily temperatures and I wanted to replicate it with my own data. Since it scales from the lowest to the highest temperature present in the data, it allows to see variations in temperature across many years. As you will probably agree, it seems that 2023 in Toronto had milder temperatures both in the Winter and in the Summer with much less prominent spikes over the entire year.\nCredits to ggHoriPlot’s vignette which had some great examples that I borrowed from.\n\nShow the codelibrary(ggHoriPlot) \nlibrary(ggthemes)\n\ncutpoints = weather_data %&gt;% \n  mutate(\n    outlier = between(\n      TEMP, \n      quantile(weather_data$TEMP, 0.25, na.rm=T)-\n        1.5*IQR(weather_data$TEMP, na.rm=T),\n      quantile(weather_data$TEMP, 0.75, na.rm=T)+\n        1.5*IQR(weather_data$TEMP, na.rm=T))) %&gt;% \n  filter(outlier)\n\nori &lt;- sum(range(cutpoints$TEMP))/2\nsca &lt;- seq(range(cutpoints$TEMP)[1], \n           range(cutpoints$TEMP)[2], \n           length.out = 7)[-4]\n\n\n\nCodeweather_data %&gt;% \n  filter(YEAR &lt;2024) %&gt;% \n  mutate(date_mine = as.Date(str_glue(\"2024-{MONTH}-{DAY}\"))) %&gt;%  #constant date, just to assemble one year on top of the other\n  ggplot() +\n  geom_horizon(aes(date_mine, \n                   TEMP,\n                   fill = ..Cutpoints..), \n               origin = ori, horizonscale = sca) +\n  scale_fill_hcl(palette = 'RdBu', reverse = T) +\n  facet_grid(YEAR~.) +\n  theme_few() +\n  scale_x_date(expand=c(0,0), \n               date_breaks = \"1 month\", \n               date_labels = \"%b\") +\n  xlab(NULL) +\n  theme(\n    panel.spacing.y=unit(0, \"lines\"),\n    strip.text.y = element_text(size = 16, angle = 0, hjust = 0),\n    axis.text.y = element_blank(),\n    axis.title.y = element_blank(),\n    axis.ticks.y = element_blank(),\n    panel.border = element_blank(),\n    legend.position = \"None\",\n    plot.title=element_text(size=20, face=\"bold\"),\n    axis.text.x = element_text(size=16,hjust=-1)\n  ) +\n  labs(title ='Daily Temperature in Toronto, Canada',x=NULL,subtitle=\"The stronger the color, the more extreme the temperature\")"
  },
  {
    "objectID": "blog_posts/scraping_pdf_tables/scraping_pdf_tables.html#how-to-get-data-from-a-table-in-your-pdf-file",
    "href": "blog_posts/scraping_pdf_tables/scraping_pdf_tables.html#how-to-get-data-from-a-table-in-your-pdf-file",
    "title": "Obtaining data from tables in PDF files",
    "section": "How to get data from a table in your PDF file",
    "text": "How to get data from a table in your PDF file\nIn order to obtain data from a tabular PDF file, you will use R package tabulizer, a fantastic tool for getting metadata and data from a PDF file. To be honest, it can be a bit tricky to install this one, though. Whenever you have to mess with Java and/or environment variables, you just know things can get messy real quick, but these are the prerequisites:\n\nJava Development Kit (JDK) installed\nEnvironment variable JAVA_HOME set to the JDK folder\nR Packages “remotes” and “rJava” installed\nRTools installed\n\nThen, you can finally execute this command to install the package:\nremotes::install_github(c(\"ropensci/tabulizerjars\", \"ropensci/tabulizer\"), INSTALL_opts = \"--no-multiarch\")\nHere is the step by step guide on how to install in much more detail if you have any difficulties:\n\nHaving done all that, now on to the good stuff:\nAnd one of the best options\n\nCodedf &lt;- data.frame(a=c(1,2,3),b=c(4,5,6)) #there you go\ndf\n\n  a b\n1 1 4\n2 2 5\n3 3 6\n\n\nThis is the first of a series of tips to come, stay tuned for more!"
  },
  {
    "objectID": "blog_posts/scraping_pdf_tables/scraping_pdf_tables.html#simpler-text",
    "href": "blog_posts/scraping_pdf_tables/scraping_pdf_tables.html#simpler-text",
    "title": "Obtaining data from tables in PDF files",
    "section": "Simple(r) text",
    "text": "Simple(r) text\nAs a first try you almost never need to deploy the biggest and more comprehensive tool; maybe the simpler and quicker method is the one that gets the job done, right? So why don’t start with a couple of simple yet very effective methods.\n1. For digital files with straightforward text - pdf_text() from pdftools\n\nWhen your PDF file contains entirely (or mostly) flowing text, it’s easier to begin with\n\nCodelibrary(pdftools)\n\nWarning: package 'pdftools' was built under R version 4.3.2\n\n\nUsing poppler version 23.08.0\n\nCodedownload.file(\"http://arxiv.org/pdf/1403.2805.pdf\", \"1403.2805.pdf\", mode = \"wb\")\ntxt &lt;- pdf_text(\"1403.2805.pdf\")\n\n# first page text\ncat(txt[1])\n\n                                              The jsonlite Package: A Practical and Consistent Mapping\n                                                                   Between JSON Data and R Objects\n\n                                                                                    Jeroen Ooms\narXiv:1403.2805v1 [stat.CO] 12 Mar 2014\n\n                                                                              UCLA Department of Statistics\n\n                                                                                             Abstract\n                                                  A naive realization of JSON data in R maps JSON arrays to an unnamed list, and JSON objects to a\n                                               named list. However, in practice a list is an awkward, inefficient type to store and manipulate data.\n                                               Most statistical applications work with (homogeneous) vectors, matrices or data frames. Therefore JSON\n                                               packages in R typically define certain special cases of JSON structures which map to simpler R types.\n                                               Currently there exist no formal guidelines, or even consensus between implementations on how R data\n                                               should be represented in JSON. Furthermore, upon closer inspection, even the most basic data structures\n                                               in R actually do not perfectly map to their JSON counterparts and leave some ambiguity for edge cases.\n                                               These problems have resulted in different behavior between implementations and can lead to unexpected\n                                               output. This paper explicitly describes a mapping between R classes and JSON data, highlights potential\n                                               problems, and proposes conventions that generalize the mapping to cover all common structures. We\n                                               emphasize the importance of type consistency when using JSON to exchange dynamic data, and illustrate\n                                               using examples and anecdotes. The jsonlite R package is used throughout the paper as a reference\n                                               implementation.\n\n                                          1    Introduction\n\n                                          JavaScript Object Notation (JSON) is a text format for the serialization of structured data (Crockford, 2006a).\n                                          It is derived from the object literals of JavaScript, as defined in the ECMAScript Programming Language\n                                          Standard, Third Edition (ECMA, 1999). Design of JSON is simple and concise in comparison with other\n                                          text based formats, and it was originally proposed by Douglas Crockford as a “fat-free alternative to XML”\n                                          (Crockford, 2006b). The syntax is easy for humans to read and write, easy for machines to parse and generate\n                                          and completely described in a single page at http://www.json.org. The character encoding of JSON text\n                                          is always Unicode, using UTF-8 by default (Crockford, 2006a), making it naturally compatible with non-\n                                          latin alphabets. Over the past years, JSON has become hugely popular on the internet as a general purpose\n                                          data interchange format. High quality parsing libraries are available for almost any programming language,\n                                          making it easy to implement systems and applications that exchange data over the network using JSON. For\n                                          R (R Core Team, 2013), several packages that assist the user in generating, parsing and validating JSON\n                                          are available through CRAN, including rjson (Couture-Beil, 2013), RJSONIO (Lang, 2013), and jsonlite\n                                          (Ooms et al., 2014).\n\n                                          The emphasis of this paper is not on discussing the JSON format or any particular implementation for using\n\n                                                                                                 1\n\nCode# second page text\ncat(txt[2])\n\nJSON with R. We refer to Nolan and Temple Lang (2014) for a comprehensive introduction, or one of the\nmany tutorials available on the web. Instead we take a high level view and discuss how R data structures are\nmost naturally represented in JSON. This is not a trivial problem, particulary for complex or relational data\nas they frequently appear in statistical applications. Several R packages implement toJSON and fromJSON\nfunctions which directly convert R objects into JSON and vice versa. However, the exact mapping between\nthe various R data classes JSON structures is not self evident. Currently, there are no formal guidelines,\nor even consensus between implementations on how R data should be represented in JSON. Furthermore,\nupon closer inspection, even the most basic data structures in R actually do not perfectly map to their\nJSON counterparts, and leave some ambiguity for edge cases. These problems have resulted in different\nbehavior between implementations, and can lead to unexpected output for certain special cases. To further\ncomplicate things, best practices of representing data in JSON have been established outside the R community.\nIncorporating these conventions where possible is important to maximize interoperability.\n\n\n1.1    Parsing and type safety\n\nThe JSON format specifies 4 primitive types (string, number, boolean, null) and two universal structures:\n\n   • A JSON object : an unordered collection of zero or more name/value pairs, where a name is a string and\n     a value is a string, number, boolean, null, object, or array.\n\n   • A JSON array: an ordered sequence of zero or more values.\n\nBoth these structures are heterogeneous; i.e. they are allowed to contain elements of different types. There-\nfore, the native R realization of these structures is a named list for JSON objects, and unnamed list for\nJSON arrays. However, in practice a list is an awkward, inefficient type to store and manipulate data in R.\nMost statistical applications work with (homogeneous) vectors, matrices or data frames. In order to give\nthese data structures a JSON representation, we can define certain special cases of JSON structures which get\nparsed into other, more specific R types. For example, one convention which all current implementations\nhave in common is that a homogeneous array of primitives gets parsed into an atomic vector instead of a\nlist. The RJSONIO documentation uses the term “simplify” for this, and we adopt this jargon.\ntxt &lt;- \"[12, 3, 7]\"\nx &lt;- fromJSON(txt)\nis(x)\n\n[1] \"numeric\" \"vector\"\n\nprint(x)\n\n[1] 12   3   7\n\nThis seems very reasonable and it is the only practical solution to represent vectors in JSON. However the\nprice we pay is that automatic simplification can compromise type-safety in the context of dynamic data.\nFor example, suppose an R package uses fromJSON to pull data from a JSON API on the web, similar to\nthe example above. However, for some particular combination of parameters, the result includes a null\nvalue, e.g: [12, null, 7]. This is actually quite common, many APIs use null for missing values or unset\nfields. This case makes the behavior of parsers ambiguous, because the JSON array is technically no longer\n\n                                                     2\n\n\nYou can see pdf_text already does a great job at identifying text and outputting into an indexed format. Even without any kind of post-processing, which is something you’ll definitely need in real-world cases, you can sometimes obtain something very clean like the output above, stored in a list with every item being one page of the file you’ve just OCR’d.\n2. scanned text - ocr() from tesseract\n\nOCR tools have evolved pretty well in the last years, especially with the evolving popularity of tesseract, an OCR engine with interfaces in Python, R and many other programming languages.1\nYou don’t even need to an image format, you can read in directly from a PDF file to try to perform the OCR:\n\nCodelibrary(tesseract)\n#ocr_result = ocr()"
  },
  {
    "objectID": "blog_posts/scraping_pdf_tables/scraping_pdf_tables.html#tables",
    "href": "blog_posts/scraping_pdf_tables/scraping_pdf_tables.html#tables",
    "title": "Obtaining data from tables in PDF files",
    "section": "Tables",
    "text": "Tables"
  }
]